flora_ts = ts(flora[, 2], start = c(1991, 1), frequency = 1)
# Plot the data without facetting(#face)
autoplot(flora_ts)
# Find the outlier in the flora_ts series
outlier <- which.max(flora_ts)
# Look at the seasonal frequencies of the flora_ts series
frequency(flora_ts)#yearly
# Create a lag plot of the flora_ts data- (plot yt against yt−1)
gglagplot(flora_ts)
# Create an ACF plot of the oil data
#The correlations associated with the lag plots form what is called the autocorrelation function (ACF)
ggAcf(flora_ts)
# Use naive() to forecast the flora_ts series
fcflora <- naive(flora_ts,h = 20)
# Plot and summarize the forecasts
autoplot(fcflora)
summary(fcflora)
# Check the residuals from the naive forecasts applied to the goog series
goog %>% naive() %>% checkresiduals()
# Check the residuals from the naive forecasts applied to the flora_ts series
flora_ts %>% naive() %>% checkresiduals()
# Do they look like white noise (TRUE or FALSE)
flora_tswn <- FALSE
# Create the training data as train
train <- subset(flora_ts, end = 20)
# Compute naive forecasts and save to naive_fc
naive_fc <- naive(flora_ts, h = 8)
# Compute mean forecasts and save to mean_fc
mean_fc <- meanf(flora_ts, h = 8)
# Use accuracy() to compute RMSE statistics
accuracy(naive_fc, flora_ts)
# Use accuracy() to compute RMSE statistics
accuracy(naive_fc, flora_ts)
# Create the training data as train
train <- subset(flora_ts, end = 20)
# Compute naive forecasts and save to naive_fc
naive_fc <- naive(flora_ts, h = 8)
# Compute mean forecasts and save to mean_fc
mean_fc <- meanf(flora_ts, h = 8)
# Use accuracy() to compute RMSE statistics
accuracy(naive_fc, flora_ts)
#load packages
library(forecast)
library(ggplot2)
library(dplyr)
# Use accuracy() to compute RMSE statistics
accuracy(naive_fc, flora_ts)
View(naive_fc)
# Create the training data as train
train <- subset(flora_ts, start = 1991, end = 2001)
# Compute naive forecasts and save to naive_fc
naive_fc <- naive(flora_ts, h = 8)
# Compute mean forecasts and save to mean_fc
mean_fc <- meanf(flora_ts, h = 8)
# Use accuracy() to compute RMSE statistics
accuracy(naive_fc, flora_ts)
View(flora)
# Create the training data as train
train <- subset(flora_ts, start = 1991, end = 2010)
# Compute naive forecasts and save to naive_fc
naive_fc <- naive(flora_ts, h = 8)
# Compute mean forecasts and save to mean_fc
mean_fc <- meanf(flora_ts, h = 8)
# Use accuracy() to compute RMSE statistics
accuracy(naive_fc, flora_ts)
length(flora_ts)-length(train)
?accuracy
# Use accuracy() to compute RMSE statistics
accuracy(naive_fc)
accuracy(mean_fc)
accuracy(mean_fc, train)
accuracy(mean_fc, flora_ts)
accuracy(naive_fc)
accuracy(mean_fc)
autoplot(naive_fc)
autoplot(mean_fc)
# Create the training data as train
train <- subset(flora_ts, start = 1991, end = 2010)
# Compute naive forecasts and save to naive_fc
naive_fc <- naive(flora_ts, h = 8)
autoplot(naive_fc)
naive_fc
# Check the residuals from the naive forecasts applied to the flora_ts series
flora_ts %>% naive() %>% checkresiduals()
rm(list=ls())
rm(list=ls())
#load packages
library(forecast)
library(ggplot2)
library(dplyr)
# Read the data from Excel into R
flora <- read.csv("C:\\Users\\user\\Desktop\\desktop folder\\data management\\R\\forecasting timeseries data\\floramdata.CSV")
# Look at the first few lines of mydata
#head(flora)
# Create a ts object called flora_ts
flora_ts = ts(flora[, 2], start = c(1991, 1), frequency = 1)
# Plot the data without facetting(#face)
autoplot(flora_ts)
# Find the outlier in the flora_ts series
outlier <- which.max(flora_ts)
# Look at the seasonal frequencies of the flora_ts series
frequency(flora_ts)#yearly
# Create a lag plot of the flora_ts data- (plot yt against yt−1)
gglagplot(flora_ts)
# Create an ACF plot of the flora_ts data
#The correlations associated with the lag plots form what is called the autocorrelation function (ACF)
ggAcf(flora_ts)
# Use naive() to forecast the flora_ts series
fcflora <- naive(flora_ts,h = 20)
# Plot and summarize the forecasts
autoplot(fcflora)
summary(fcflora)
# Check the residuals from the naive forecasts applied to the flora_ts series
flora_ts %>% naive() %>% checkresiduals()
# Do they look like white noise (TRUE or FALSE)
flora_tswn <- FALSE
# Create the training data as train
train <- subset(flora_ts, start = 1991, end = 2010)
# Compute naive forecasts and save to naive_fc
naive_fc <- naive(flora_ts, h = 8)
autoplot(naive_fc)
# Compute mean forecasts and save to mean_fc
mean_fc <- meanf(flora_ts, h = 8)
autoplot(mean_fc)
# Use accuracy() to compute RMSE statistics
accuracy(naive_fc)
accuracy(mean_fc)
# Assign one of the two forecasts as bestforecasts
bestforecasts <- naive_fc
133000
12
133000/12
133000/12*100
library("ggplot2", lib.loc="~/R/win-library/3.5")
?remove
?shape
pi*(3-sqrt(5))
angle <- 13*pi/180
points <- 2000
#my_first_flower
library(ggplot2)
t <- (1:points)*angle
x <- sin(t)
y <- cos(t)
df <- data.frame(t, x, y)
p <- ggplot(df, aes(x*t, y*t))
p + geom_point(size = 80, alpha = 0.1, color = "magenta4", shape = 1) +
theme(panel.background = element_rect(fill = "white"),
panel.grid = element_blank(),
title = element_blank(),
text = element_blank(),
axis.ticks = element_blank(),
legend.position = "none")
rm(list = ls())
x <- 20
y <- 4
x %% y
library(tidyr)
install.packages("lavaan")
rm(list = ls())
##SEM
library(lavaan)
Ghedi_data <- read.csv("C:\\stata assignments\\almost complete\\masters for march\\PHD Mohammed Ghedi\\CLEAN SURVEY DATA.xlsx")
##SEM
library(xlsx)
##SEM
library(xlsx)
library("xlsx", lib.loc="~/R/win-library/3.5")
install.packages("xlsx")
##SEM
library(xlsx)
library("xlsx", lib.loc="~/R/win-library/3.5")
Ghedi_data <- readxl::read_xlsx("C:\\stata assignments\\almost complete\\masters for march\\PHD Mohammed Ghedi\\CLEAN SURVEY DATA.xlsx")
View(Ghedi_data)
names(Ghedi_data)
rm(list = ls())
##SEM
library(xlsx)
library(lavaan)
#ONE_FACTOR_MODEL_ANALYSIS
Ghedi_data <- readxl::read_xlsx("C:\\stata assignments\\almost complete\\masters for march\\PHD Mohammed Ghedi\\CLEAN SURVEY DATA.xlsx")
# Look at the dataset
data(Ghedi_data)
head(Ghedi_data)
#INDEPENDENT VARIABLE1
Knowledge_Conversion_Socialization.model <- "KnowledgeConversionSocialization =~ BS1 + BS2 +BS3"
Knowledge_Conversion_Externalization.model <- "KnowledgeConversionExternalization =~ BE1 + BE2"
Knowledge_Conversion_Combination.model <- "KnowledgeConversionCombination =~ BC1 + BC2 +BC3 + BC4 + BC5"
Knowledge_Conversion_Internalization.model <- "KnowledgeConversionInternalization =~  BI1 + BI2 + BI3"
Knowledge_Conversion.model <- "knwclatent =~ BS1 + BS2 +BS3 +BE1 + BE2 + BC1 + BC2 +BC3 + BC4 + BC5 + BI1 + BI2 + BI3"
#INDEPENDENT VARIABLE2
Knowledge_Transfer.model <- "KnowledgeTransfer =~ C1 + C2 + C3 + C4 + C5 + C6"
#INDEPENDENT VARIABLE 3
Knowledge_Application.model <- "KnowledgeApplication =~ D1 + D2 + D3 + D4 + D5 + D6"
#INDEPENDENT VARIABLE 4
Human_Capital_Repository.model <- "HumanCapitalRepositoryExperience =~ EEX1 + EEX2 + EEX3 + EEX4 + EEX5"
Human_Capital_Repository.model <- "HumanCapitalRepositoryEducation =~ EED1 + EED2 + EED3 + EED4 + EED5 + EED6 + EED7"
Human_Capital_Repository.model <- "HumanCapitalRepositoryInnovativeness =~ EI1 + EI2 + EI3 + EI4 + EI5"
Human_Capital_Repository.model <- "HumanCapitalRepository =~ EEX1 + EEX2 + EEX3 + EEX4 + EEX5 + EED1 + EED2 + EED3 + EED4 + EED5 + EED6 + EED7 + EI1 + EI2 + EI3 + EI4 + EI5"
#INDEPENDENT VARIABLE 5
Firm_Culture_Openness.model <- "FirmCultureOpenness =~ FO1 + FO2 + FO3 + FO4"
Firm_Culture_Futuristic orientation.model <- "FirmCultureFuturistic orientation  =~ FF1 + FF2 + FF3 + FF4"
Firm_Culture_Learning_orientation.model <- "FirmCultureLearning orientation  =~ FL1 + FL2 + FL3 + FL4 + FL5"
#DEPENDENT VARIABLE
Performance.model <- "Performance =~ KM1 + KM2 +KM3 + KM4 + KM5 + KM6"
rm(list = ls())
##SEM
library(xlsx)
library(lavaan)
#ONE_FACTOR_MODEL_ANALYSIS
Ghedi_data <- readxl::read_xlsx("C:\\stata assignments\\almost complete\\masters for march\\PHD Mohammed Ghedi\\CLEAN SURVEY DATA.xlsx")
# Look at the dataset
data(Ghedi_data)
head(Ghedi_data)
#INDEPENDENT VARIABLE1
Knowledge_Conversion_Socialization.model <- "KnowledgeConversionSocialization =~ BS1 + BS2 +BS3"
Knowledge_Conversion_Externalization.model <- "KnowledgeConversionExternalization =~ BE1 + BE2"
Knowledge_Conversion_Combination.model <- "KnowledgeConversionCombination =~ BC1 + BC2 +BC3 + BC4 + BC5"
Knowledge_Conversion_Internalization.model <- "KnowledgeConversionInternalization =~  BI1 + BI2 + BI3"
Knowledge_Conversion.model <- "knwclatent =~ BS1 + BS2 +BS3 +BE1 + BE2 + BC1 + BC2 +BC3 + BC4 + BC5 + BI1 + BI2 + BI3"
#INDEPENDENT VARIABLE2
Knowledge_Transfer.model <- "KnowledgeTransfer =~ C1 + C2 + C3 + C4 + C5 + C6"
#INDEPENDENT VARIABLE 3
Knowledge_Application.model <- "KnowledgeApplication =~ D1 + D2 + D3 + D4 + D5 + D6"
#INDEPENDENT VARIABLE 4
Human_Capital_Repository.model <- "HumanCapitalRepositoryExperience =~ EEX1 + EEX2 + EEX3 + EEX4 + EEX5"
Human_Capital_Repository.model <- "HumanCapitalRepositoryEducation =~ EED1 + EED2 + EED3 + EED4 + EED5 + EED6 + EED7"
Human_Capital_Repository.model <- "HumanCapitalRepositoryInnovativeness =~ EI1 + EI2 + EI3 + EI4 + EI5"
Human_Capital_Repository.model <- "HumanCapitalRepository =~ EEX1 + EEX2 + EEX3 + EEX4 + EEX5 + EED1 + EED2 + EED3 + EED4 + EED5 + EED6 + EED7 + EI1 + EI2 + EI3 + EI4 + EI5"
#INDEPENDENT VARIABLE 5
Firm_Culture_Openness.model <- "FirmCultureOpenness =~ FO1 + FO2 + FO3 + FO4"
Firm_Culture_Futuristic orientation.model <- "FirmCultureFuturisticorientation  =~ FF1 + FF2 + FF3 + FF4"
Firm_Culture_Learning_orientation.model <- "FirmCultureLearning orientation  =~ FL1 + FL2 + FL3 + FL4 + FL5"
#DEPENDENT VARIABLE
Performance.model <- "Performance =~ KM1 + KM2 +KM3 + KM4 + KM5 + KM6"
rm(list = ls())
##SEM
library(xlsx)
library(lavaan)
#ONE_FACTOR_MODEL_ANALYSIS
Ghedi_data <- readxl::read_xlsx("C:\\stata assignments\\almost complete\\masters for march\\PHD Mohammed Ghedi\\CLEAN SURVEY DATA.xlsx")
# Look at the dataset
data(Ghedi_data)
head(Ghedi_data)
#INDEPENDENT VARIABLE1
Knowledge_Conversion_Socialization.model <- "KnowledgeConversionSocialization =~ BS1 + BS2 +BS3"
Knowledge_Conversion_Externalization.model <- "KnowledgeConversionExternalization =~ BE1 + BE2"
Knowledge_Conversion_Combination.model <- "KnowledgeConversionCombination =~ BC1 + BC2 +BC3 + BC4 + BC5"
Knowledge_Conversion_Internalization.model <- "KnowledgeConversionInternalization =~  BI1 + BI2 + BI3"
Knowledge_Conversion.model <- "knwclatent =~ BS1 + BS2 +BS3 +BE1 + BE2 + BC1 + BC2 +BC3 + BC4 + BC5 + BI1 + BI2 + BI3"
#INDEPENDENT VARIABLE2
Knowledge_Transfer.model <- "KnowledgeTransfer =~ C1 + C2 + C3 + C4 + C5 + C6"
#INDEPENDENT VARIABLE 3
Knowledge_Application.model <- "KnowledgeApplication =~ D1 + D2 + D3 + D4 + D5 + D6"
#INDEPENDENT VARIABLE 4
Human_Capital_Repository.model <- "HumanCapitalRepositoryExperience =~ EEX1 + EEX2 + EEX3 + EEX4 + EEX5"
Human_Capital_Repository.model <- "HumanCapitalRepositoryEducation =~ EED1 + EED2 + EED3 + EED4 + EED5 + EED6 + EED7"
Human_Capital_Repository.model <- "HumanCapitalRepositoryInnovativeness =~ EI1 + EI2 + EI3 + EI4 + EI5"
Human_Capital_Repository.model <- "HumanCapitalRepository =~ EEX1 + EEX2 + EEX3 + EEX4 + EEX5 + EED1 + EED2 + EED3 + EED4 + EED5 + EED6 + EED7 + EI1 + EI2 + EI3 + EI4 + EI5"
#INDEPENDENT VARIABLE 5
Firm_Culture_Openness.model <- "FirmCultureOpenness =~ FO1 + FO2 + FO3 + FO4"
Firm_Culture_Futuristic orientation.model <- "FirmCultureFuturisticorientation  =~ FF1 + FF2 + FF3 + FF4"
Firm_Culture_Learning_orientation.model <- "FirmCultureLearningorientation  =~ FL1 + FL2 + FL3 + FL4 + FL5"
#DEPENDENT VARIABLE
Performance.model <- "Performance =~ KM1 + KM2 +KM3 + KM4 + KM5 + KM6"
rm(list = ls())
##SEM
library(xlsx)
library(lavaan)
#ONE_FACTOR_MODEL_ANALYSIS
Ghedi_data <- readxl::read_xlsx("C:\\stata assignments\\almost complete\\masters for march\\PHD Mohammed Ghedi\\CLEAN SURVEY DATA.xlsx")
# Look at the dataset
data(Ghedi_data)
head(Ghedi_data)
#INDEPENDENT VARIABLE1
Knowledge_Conversion_Socialization.model <- "KnowledgeConversionSocialization =~ BS1 + BS2 +BS3"
Knowledge_Conversion_Externalization.model <- "KnowledgeConversionExternalization =~ BE1 + BE2"
Knowledge_Conversion_Combination.model <- "KnowledgeConversionCombination =~ BC1 + BC2 +BC3 + BC4 + BC5"
Knowledge_Conversion_Internalization.model <- "KnowledgeConversionInternalization =~  BI1 + BI2 + BI3"
Knowledge_Conversion.model <- "knwclatent =~ BS1 + BS2 +BS3 +BE1 + BE2 + BC1 + BC2 +BC3 + BC4 + BC5 + BI1 + BI2 + BI3"
#INDEPENDENT VARIABLE2
Knowledge_Transfer.model <- "KnowledgeTransfer =~ C1 + C2 + C3 + C4 + C5 + C6"
#INDEPENDENT VARIABLE 3
Knowledge_Application.model <- "KnowledgeApplication =~ D1 + D2 + D3 + D4 + D5 + D6"
#INDEPENDENT VARIABLE 4
Human_Capital_Repository.model <- "HumanCapitalRepositoryExperience =~ EEX1 + EEX2 + EEX3 + EEX4 + EEX5"
Human_Capital_Repository.model <- "HumanCapitalRepositoryEducation =~ EED1 + EED2 + EED3 + EED4 + EED5 + EED6 + EED7"
Human_Capital_Repository.model <- "HumanCapitalRepositoryInnovativeness =~ EI1 + EI2 + EI3 + EI4 + EI5"
Human_Capital_Repository.model <- "HumanCapitalRepository =~ EEX1 + EEX2 + EEX3 + EEX4 + EEX5 + EED1 + EED2 + EED3 + EED4 + EED5 + EED6 + EED7 + EI1 + EI2 + EI3 + EI4 + EI5"
#INDEPENDENT VARIABLE 5
Firm_Culture_Openness.model <- "FirmCultureOpenness =~ FO1 + FO2 + FO3 + FO4"
Firm_Culture_Futuristic_orientation.model <- "FirmCultureFuturisticorientation  =~ FF1 + FF2 + FF3 + FF4"
Firm_Culture_Learning_orientation.model <- "FirmCultureLearningorientation  =~ FL1 + FL2 + FL3 + FL4 + FL5"
#DEPENDENT VARIABLE
Performance.model <- "Performance =~ KM1 + KM2 +KM3 + KM4 + KM5 + KM6"
# Analysis of the dependent models
perform.fit <- cfa(Performance.model,Ghedi_data)
summary(perform.fit)
summary(perform.fit, standardized = TRUE)
summary(perform.fit, standardized = TRUE, fit,measures = TRUE)
summary(perform.fit, standardized = TRUE, fit.measures = TRUE)
install.packages("devtools")
install.packages("plotly")
py <- plotly(username="r_user_guide", key="mw5isa4yqp")  # open plotly connection
library("devtools")
library(plotly)
py <- plotly(username="r_user_guide", key="mw5isa4yqp")  # open plotly connection
pp <- function (n,r=4) {
x <- seq(-r*pi, r*pi, len=n)
df <- expand.grid(x=x, y=x)
df$r <- sqrt(df$x^2 + df$y^2)
df$z <- cos(df$r^2)*exp(-df$r/6)
df
}
p <- ggplot(pp(20), aes(x=x,y=y))
p <- p + geom_tile(aes(fill=z))
py$ggplotly(p)
---
title: "Hello R Markdown"
author: "Victor Mandela"
date: "May 15, 2019"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## R Markdown
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r cars}
summary(cars)
```
## Including Plots
You can also embed plots, for example:
```{r pressure, echo=FALSE}
plot(pressure)
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
install.packages("nasaweather")
install.packages("ggvis")
library(nasaweather)
library(dplyr)
library(ggvis)
year <- 1995
means <- atmos %>%
filter(year == year) %>%
group_by(long, lat)
means
means <- atmos %>%
filter(year == year) %>%
group_by(long, lat)%>%
summarize(temp = mean(temp, na.rm = TRUE),
pressure = mean(pressure, na.rm = TRUE),
ozone = mean(ozone, na.rm = TRUE),
cloudlow = mean(cloudlow, na.rm = TRUE),
cloudmid = mean(cloudmid, na.rm = TRUE),
cloudhigh = mean(cloudhigh, na.rm = TRUE)) %>%
ungroup()
# Inspect the means variable
means
means <- atmos %>%
filter(year == year) %>%
group_by(long, lat)%>%
summarize(temp = mean(temp, na.rm = TRUE),
pressure = mean(pressure, na.rm = TRUE),
ozone = mean(ozone, na.rm = TRUE),
cloudlow = mean(cloudlow, na.rm = TRUE),
cloudmid = mean(cloudmid, na.rm = TRUE),
cloudhigh = mean(cloudhigh, na.rm = TRUE))
means
# Change the code to plot the temp variable vs the ozone variable
means %>%
ggvis(x = ~pressure, y = ~ozone) %>%
layer_points()
?barplot
rm(list=l)
rm(list=ls())
2+1
5*3
8/4
8//4
2^3
v <- as.vector(seq(1,10))
v
v1 <- as.vector(seq(11,20))
v1
length(v1)
t(v1)
v2 <- 3*v1
v2
outer_prod <- v3 %*% t(v3)
v3 <- as.vector(seq(1,5))
outer_prod <- v3 %*% t(v3)
outer_prod
v3
mean(v)
var(v)
sd(v)
source('C:/Users/user/Desktop/desktop folder/data management/R/teaching R to first timers.R', echo=TRUE)
source('C:/Users/user/Desktop/desktop folder/data management/R/teaching R to first timers.R', echo=TRUE)
vm
vm<- cbind(v1, v2, v3)
vm<- cbind(v1, v2, v3)
vm
dim(vm)
vmm<- cbind(vm,vm)
vmm
ds <- summary(vmm)
ds
datasets()
?datasets
library(help = "datasets")
data(ChickWeight)
data(BJsales)
View(BJsales)
str(BJsales)
BJsales
mean(BJsales)
mean(DS)
summary()
summary(BJsales
)
plot(BJsales)
ChickWeight
ChickWeight()
str(ChickWeight)
?lm
setwd("C:/stata assignments/almost complete/masters for march/interview questions")
data1 <- read.csv(Ongoza Data Science Intern _ Analyst Case Study - Data (1))
setwd("C:/stata assignments/almost complete/masters for march/interview questions/Victor_Mandela_MLIS")
data <- read.csv("mm.csv")
data
head(data)
tail(data)
View(data)
revenue <- data$fins_revenues_m1
since <- data$fins_revenues_sincefound
revenue
y<-data$fins_revenues_m1
x<-data$fins_revenues_sincefound
y,x
y
x
help(lm)
lm(y~x)
x2 <- data$found_name1_age
slr <- lm(y~x1)
mlr <- lm(y~x1+x2)
y <- data$fins_revenues_m1
x1 <- data$fins_revenues_sincefound
x2 <- data$found_name1_age
slr <- lm(y~x1)
mlr <- lm(y~x1+x2)
slr <- lm(y~x1);slr
mlr <- lm(y~x1+x2);mlr
?`datasets
>
#creating a matrix
A<-matrix(c(1,2,3,4,5,6,7,8,9,10,11,12), byrow = TRUE, nrow = 3)
#creating a matrix
A<-matrix(c(1,2,3,4,5,6,7,8,9,10,11,12), byrow = TRUE, nrow = 3);A
A
A<-matrix(c(1,2,3,4,5,6,7,8,9,10,11,12), byrow = TRUE, nrow = 3)
B<-matrix(c(10:22),byrow = TRUE ,nrow=3)
B
A<-matrix(c(1,2,3,4,5,6,7,8,9,10,11,12), byrow = TRUE, nrow = 3)
B<-matrix(c(10:22),byrow = TRUE ,nrow=3)
B
#Basic matrix operations
#addition
add<-A+B;add
sub<- A-B;sub
mult<-A%*%B;mult
#do not use the asterik without the percentage signs
A<-matrix(c(1,2,3,4,5,6,7,8,9,10,11,12), byrow = TRUE, nrow = 3)
B<-matrix(c(10:22),byrow = TRUE ,nrow=3)
B
#Basic matrix operations
#addition
add<-A+B;add
sub<- A-B;sub
mult<-A%*%B;mult
#do not use the asterik without the percentage signs
multind<-A*B;multind
#multiply individual elements: it does not run
trans<-t(A)
Inverse<-solve(A)#also/or you can use
inv(A)
Eigen<-eigen(A)
Vector.mult<-4*A
#creating a matrix
A<-matrix(c(1,2,3,4,5,6,7,8,9,10,11,12), byrow = TRUE, nrow = 3)
B<-matrix(c(10:22),byrow = TRUE ,nrow=3)
B<-matrix(c(10:21),byrow = TRUE ,nrow=3)
B
#Basic matrix operations
#addition
add<-A+B;add
sub<- A-B;sub
mult<-A%*%B;mult
#do not use the asterik without the percentage signs
multind<-A*B;multind
#multiply individual elements: it does not run
trans<-t(A)
Inverse<-solve(A)#also/or you can use
inv(A)
Eigen<-eigen(A)
Vector.mult<-4*A
determinant<- det(A)
q()
